# -*- coding: utf-8 -*-
"""SquatModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZVawrRw8j7GjcZE5c9JvJpcPr982kNBQ
"""


# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Squat2
# %ls
data_dir = "C:/Users/HUSTAR12/Desktop/Squat"
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from sklearn.utils import class_weight
import numpy as np
data_dir = 'C:/Users/HUSTAR12/Desktop/Squat/Dataset'
tf.keras.backend.set_floatx('float64')
epochs = 10
drop = 0.5
img_size = (128,128)

model = Sequential([
    Conv2D(8, 5, activation=tf.keras.layers.LeakyReLU(alpha=0.1), input_shape = (img_size[0], img_size[1], 1)),
    MaxPool2D(3),
    Conv2D(16, 4, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),
    MaxPool2D(2),
    Conv2D(32, 3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),
    Flatten(),
    Dense(32, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),
    Dropout(drop),
    Dense(8, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),
    Dense(3, activation = 'softmax')
])

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
#####################################################################################################
# batch_size = 16
# img_height = 128
# img_width = 128
# train_ds = tf.keras.preprocessing.image_dataset_from_directory(
#   data_dir,
#   validation_split=0.2,
#   subset="training",
#   seed=123,
#   image_size=(img_height, img_width),
#   batch_size=batch_size)

# val_ds = tf.keras.preprocessing.image_dataset_from_directory(
#   data_dir,
#   validation_split=0.2,
#   subset="validation",
#   seed=123,
#   image_size=(img_height, img_width),
#   batch_size=batch_size)

#####################################################################################
# 트레이닝 데이터셋 나누기
#####################################################################################

#####################################################################################

datagen = ImageDataGenerator(
    rescale = 1. / 255.,
    shear_range = 0.2,
    zoom_range = 0.05,
    rotation_range = 10,
    width_shift_range = 0.1,
    height_shift_range = 0.05,
    brightness_range = [1, 1.5],
    horizontal_flip = True,
    dtype = tf.float64)

train_generator = datagen.flow_from_directory(
    'C:/Users/HUSTAR12/Desktop/Squat/Dataset/Train_data',
    target_size = img_size,
    color_mode = 'grayscale',
    batch_size = 32,
    shuffle = True,
    class_mode='categorical')

test_datagen = ImageDataGenerator(
    rescale = 1. / 255.,
    dtype = tf.float64)


test_generator = test_datagen.flow_from_directory(
    'C:/Users/HUSTAR12/Desktop/Squat/Dataset/Validation_data',
    target_size = img_size,
    color_mode = 'grayscale',
    batch_size = 16,
    shuffle = True,
    class_mode='categorical')


class_weights = class_weight.compute_class_weight(
                   'balanced',
                   np.unique(train_generator.classes), 
                   train_generator.classes)


history = model.fit(train_generator, 
          validation_data = test_generator,
          epochs = epochs,
          shuffle = True,
      #   validation_split=0.2,
      ##  class_weight = class_weights,
          workers = 8,
          max_queue_size = 512)

model.save('saved/saved11.h5')
###################################################################


acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss=history.history['loss']
val_loss=history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()